slug: "interpreter"
name: "Build your own Interpreter"
short_name: "Interpreter"
release_status: "alpha"

description_md: |-
  This challenge follows the book [Crafting Interpreters](https://craftinginterpreters.com/) by Robert Nystrom.

  In this challenge you'll build an interpreter for [Lox](https://craftinginterpreters.com/the-lox-language.html), a simple scripting
  language. Along the way, you'll learn about tokenization, ASTs, tree-walk interpreters and more.

  Before starting this challenge, make sure you've read the "Welcome" part of the book that contains these chapters:

  - [Introduction](https://craftinginterpreters.com/introduction.html) (chapter 1)
  - [A Map of the Territory](https://craftinginterpreters.com/a-map-of-the-territory.html) (chapter 2)
  - [The Lox Language](https://craftinginterpreters.com/the-lox-language.html) (chapter 3)

  These chapters don't involve writing code, so they won't be covered in this challenge. This challenge will start
  from chapter 4, [Scanning](https://craftinginterpreters.com/scanning.html).

short_description_md: |-
  Learn about tokenization, ASTs, tree-walk interpreters and more.

completion_percentage: 15

languages:
  - slug: "go"
  - slug: "python"
  - slug: "rust"

marketing:
  difficulty: hard
  sample_extension_idea_title: "Control flow"
  sample_extension_idea_description: "An interpreter that can handle control flow statements like if/else"
  testimonials:
    - author_name: "Ananthalakshmi Sankar"
      author_description: "Automation Engineer at Apple"
      author_avatar: "https://codecrafters.io/images/external/testimonials/oxta.jpeg"
      link: "https://github.com/anu294"
      text: "There are few sites I like as much that have a step by step guide. The real-time feedback is so good, it's creepy!"

    - author_name: "Patrick Burris"
      author_description: "Senior Software Developer, CenturyLink"
      author_avatar: "https://codecrafters.io/images/external/testimonials/patrick-burris.jpeg"
      link: "https://github.com/Jumballaya"
      text: |-
        I think the instant feedback right there in the git push is really cool.
        Didn't even know that was possible!

stages:
  - slug: "ry8"
    name: "Scanning: Empty file"
    difficulty: very_easy
    description_md: |-
      Before starting this stage, make sure you've read the "Welcome" section of the book that contains these chapters:

      - [Introduction](https://craftinginterpreters.com/introduction.html) (chapter 1)
      - [A Map of the Territory](https://craftinginterpreters.com/a-map-of-the-territory.html) (chapter 2)
      - [The Lox Language](https://craftinginterpreters.com/the-lox-language.html) (chapter 3)

      These chapters don't involve writing code, so they won't be covered in this challenge. This challenge will start
      from chapter 4, [Scanning](https://craftinginterpreters.com/scanning.html).

      ---

      In this stage, you'll implement basic support for the `tokenize` command.

      ### The `tokenize` command

      The `tokenize` command tokenizes a Lox program and prints the tokens to stdout. We'll use this for testing
      all stages in the [Scanning](https://craftinginterpreters.com/scanning.html) chapter.

      If there's a file named `test.lox` with the following contents:

      ```bash
      var language = "lox";
      ```

      The `tokenize` command will return the following:

      ```bash
      $ ./your_program.sh tokenize test.lox
      VAR var null
      IDENTIFIER language null
      EQUAL = null
      STRING "lox" lox
      SEMICOLON ; null
      EOF  null
      ```

      This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning).

      Each line corresponds to a token in the file (Image from [Section 4.2: Lexemes & Tokens](https://craftinginterpreters.com/scanning.html#lexemes-and-tokens)):

      ![img](https://craftinginterpreters.com/image/scanning/lexemes.png)

      This is the format for each line:

      ```
      <token_type> <lexeme> <literal>
      ```

      - `<token_type>`: The type of the token.
        - Examples: `VAR`, `IDENTIFIER`, `STRING`, `EOF` etc.
      - `<lexeme>`: The actual sequence of characters that formed the token.
        - Examples: `var`, `breakfast`, `"bagels"` etc.
        - For an `EOF` token, the lexeme is an empty string.
      - `<literal>`: The literal value of the token.
        - For most tokens this is `null`.
        - For `STRING`/`NUMBER` tokens, it holds the value of the string/number.

      The `EOF` token is a special token that represents the end of the file. All calls to `tokenize` will include an `EOF` token at the end.

      ### Tests

      The tester will write an empty file to `test.lox`. It'll then run your program like this:

      ```bash
      $ ./your_program.sh tokenize test.lox
      EOF  null
      ```

      Since the file is empty, only one token is expected in the output: `EOF`. The tester will verify that `EOF<space><space>null` is printed to stdout.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - There are two spaces between `EOF` and `null`. This is because the `<lexeme>` part is an empty string for the `EOF` token.
    marketing_md: |-
      In this stage, you'll implement basic support for the `tokenize` command which we'll use in all stages that are part of the [Scanning](https://craftinginterpreters.com/scanning.html) chapter.

  - slug: "ol4"
    name: "Scanning: Parentheses"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning parentheses.

      ### Book reference

      The code for this stage is implemented in [Section 4.2: Recognizing Lexemes](https://craftinginterpreters.com/scanning.html#recognizing-lexemes).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain parentheses.

      For example, if `test.lox` contains the following:

      ```bash
      (()
      ```

      The tester will run your program like this:

      ```bash
      $ ./your_program.sh tokenize test.lox
      LEFT_PAREN ( null
      LEFT_PAREN ( null
      RIGHT_PAREN ) null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning parentheses.

  - slug: "oe8"
    name: "Scanning: Braces"
    difficulty: easy
    description_md: |-
      In this stage, you'll add support for scanning braces.

      ### Book reference

      The code for this stage is implemented in [Section 4.2: Recognizing Lexemes](https://craftinginterpreters.com/scanning.html#recognizing-lexemes).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain braces combined with parentheses.

      For example, if `test.lox` contains the following:

      ```bash
      {{}}
      ```

      The tester will run your program like this:

      ```bash
      $ ./your_program.sh tokenize test.lox
      LEFT_BRACE { null
      LEFT_BRACE { null
      RIGHT_BRACE } null
      RIGHT_BRACE } null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning braces.

  - slug: "xc5"
    name: "Scanning: Other single-character tokens"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning other single-character tokens, like ",", ".", "-", "+", ";", "*".
      "/" is not covered here, it's coved in later stages. 

      ### Book reference

      # TODO Section is wrong. 4.2 ?
      The code for this stage is implemented in [Section 4.2: Recognizing Lexemes](https://craftinginterpreters.com/scanning.html#recognizing-lexemes).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain parentheses, braces combined with all the new single-character tokens.

      For example, if `test.lox` contains the following:

      ```bash
      ({*.,+*})
      ```

      The tester will run your program like this:

      ```bash
      $ ./your_program.sh tokenize test.lox
      LEFT_PAREN ( null
      LEFT_BRACE { null
      STAR * null
      DOT . null
      COMMA , null
      PLUS + null
      STAR * null
      RIGHT_BRACE } null
      RIGHT_PAREN ) null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning other single-character tokens.

  - slug: "ea6"
    name: "Scanning: Lexical errors"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning tokens, that lead to a lexical error.

      ### Book reference

      The code for this stage is implemented in [Section 4.5.1: Lexical Errors](https://craftinginterpreters.com/scanning.html#lexical-errors).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain unknown tokens mixed with all previously introduced token types.

      For example, if `test.lox` contains the following:

      ```bash
      ,.$(#
      ```

      The tester will run your program like this:

      ```bash
      $ ./your_program.sh tokenize test.lox
      [line 1] Error: Unexpected character: $
      [line 1] Error: Unexpected character: #
      COMMA , null
      DOT . null
      LEFT_PAREN ( null
      EOF  null
      ```

      The lexical errors, should be printed to the stderr stream, with the `[line N]` prefix at the beginning. 
      The tester will assert that the stdout stream of your program matches the valid tokens, and the stderr stream contains the lexical errors. 

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
      - You can use the stderr stream to print debug logs for your own use too, to register a line as an error, it has to contain the `[line N]` prefix. Else we will ignore it as an user log. 
      - As the stdout and stderr are completely different streams, the order of errors and valid tokens don't matter. 
      - Also keep in mind the exit code, needs to be 65 if you encounter lexical errors. 
    marketing_md: |-
      In this stage, you'll implement support for scanning lexical errors.
